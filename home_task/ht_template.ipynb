{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f, types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/22 23:58:45 WARN Utils: Your hostname, anatoliidomanskii-System-Product-Name resolves to a loopback address: 127.0.1.1; using 192.168.1.25 instead (on interface enp5s0)\n",
      "22/10/22 23:58:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/22 23:58:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('lect_13_home_task').getOrCreate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "actor_df = spark.read.csv('./data/actor.csv', header=True, inferSchema=True)\n",
    "address_df = spark.read.csv('./data/address.csv', header=True, inferSchema=True)\n",
    "category_df = spark.read.csv('./data/category.csv', header=True, inferSchema=True)\n",
    "city_df = spark.read.csv('./data/city.csv', header=True, inferSchema=True)\n",
    "country_df = spark.read.csv('./data/country.csv', header=True, inferSchema=True)\n",
    "customer_df = spark.read.csv('./data/customer.csv', header=True, inferSchema=True)\n",
    "film_df = spark.read.csv('./data/film.csv', header=True, inferSchema=True)\n",
    "film_actor_df = spark.read.csv('./data/film_actor.csv', header=True, inferSchema=True)\n",
    "film_category_df = spark.read.csv('./data/film_category.csv', header=True, inferSchema=True)\n",
    "inventory_df = spark.read.csv('./data/inventory.csv', header=True, inferSchema=True)\n",
    "language_df = spark.read.csv('./data/language.csv', header=True, inferSchema=True)\n",
    "payment_df = spark.read.csv('./data/payment.csv', header=True, inferSchema=True)\n",
    "rental_df = spark.read.csv('./data/rental.csv', header=True, inferSchema=True)\n",
    "staff_df = spark.read.csv('./data/staff.csv', header=True, inferSchema=True)\n",
    "store_df = spark.read.csv('./data/store.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Домашнє завдання на тему Spark SQL\n",
    "\n",
    "Задачі з домашнього завдання на SQL потрібно розвʼязати за допомогою Spark SQL DataFrame API.\n",
    "\n",
    "- Дампи таблиць знаходяться в папці `data`. Датафрейми таблиць вже створені в клітинці вище.\n",
    "- Можете створювати стільки нових клітинок, скільки вам необхідно.\n",
    "- Розвʼязок кожної задачі має бути відображений в самому файлі (використати метод `.show()`)\n",
    "\n",
    "**Увага!**\n",
    "Використовувати мову запитів SQL безпосередньо забороняється, потрібно використовувати виключно DataFrame API!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.\n",
    "Вивести кількість фільмів в кожній категорії.\n",
    "Результат відсортувати за спаданням."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|       name|num_of_films|\n",
      "+-----------+------------+\n",
      "|     Sports|          74|\n",
      "|    Foreign|          73|\n",
      "|     Family|          69|\n",
      "|Documentary|          68|\n",
      "|  Animation|          66|\n",
      "|     Action|          64|\n",
      "|        New|          63|\n",
      "|      Drama|          62|\n",
      "|      Games|          61|\n",
      "|     Sci-Fi|          61|\n",
      "|   Children|          60|\n",
      "|     Comedy|          58|\n",
      "|     Travel|          57|\n",
      "|   Classics|          57|\n",
      "|     Horror|          56|\n",
      "|      Music|          51|\n",
      "+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_category_df.\\\n",
    "    join(category_df, film_category_df.category_id==category_df.category_id, 'left').\\\n",
    "    groupby(category_df.name).\\\n",
    "    agg(f.count('film_id').alias('num_of_films')).\\\n",
    "    orderBy(f.desc('num_of_films')).\\\n",
    "    show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.\n",
    "Вивести 10 акторів, чиї фільми брали на прокат найбільше.\n",
    "Результат відсортувати за спаданням."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---+\n",
      "|first_name|  last_name|qty|\n",
      "+----------+-----------+---+\n",
      "|     SUSAN|      DAVIS|825|\n",
      "|      GINA|  DEGENERES|753|\n",
      "|   MATTHEW|     CARREY|678|\n",
      "|      MARY|     KEITEL|674|\n",
      "|    ANGELA|WITHERSPOON|654|\n",
      "|    WALTER|       TORN|640|\n",
      "|     HENRY|      BERRY|612|\n",
      "|     JAYNE|      NOLTE|611|\n",
      "|       VAL|     BOLGER|605|\n",
      "|    SANDRA|     KILMER|604|\n",
      "+----------+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_df.\\\n",
    "    join(inventory_df, rental_df.inventory_id==inventory_df.inventory_id, 'left').\\\n",
    "    join(film_actor_df, inventory_df.film_id==film_actor_df.film_id, 'left').\\\n",
    "    join(actor_df, film_actor_df.actor_id==actor_df.actor_id).\\\n",
    "    where(actor_df.actor_id.isNotNull()).\\\n",
    "    groupby(actor_df.first_name, actor_df.last_name).\\\n",
    "    agg(f.count(rental_df.rental_id).alias('qty')).\\\n",
    "    orderBy(f.desc('qty')).\\\n",
    "    limit(10).\\\n",
    "    show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.\n",
    "Вивести категорія фільмів, на яку було витрачено найбільше грошей\n",
    "в прокаті"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|  name|         payments|\n",
      "+------+-----------------+\n",
      "|Sports|5314.209999999847|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_df.\\\n",
    "    join(rental_df, payment_df.rental_id==rental_df.rental_id, 'left').\\\n",
    "    join(inventory_df, rental_df.inventory_id==inventory_df.inventory_id, 'left').\\\n",
    "    join(film_category_df, inventory_df.film_id==film_category_df.film_id, 'left').\\\n",
    "    join(category_df, film_category_df.category_id==category_df.category_id, 'left').\\\n",
    "    groupby(category_df.name).\\\n",
    "    agg(f.sum(payment_df.amount).alias('payments')).\\\n",
    "    orderBy(f.desc('payments')).\\\n",
    "    limit(1).\\\n",
    "    show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.\n",
    "Вивести назви фільмів, яких не має в inventory.\n",
    "Запит має бути без оператора IN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|      ALICE FANTASIA|\n",
      "|         APOLLO TEEN|\n",
      "|      ARGONAUTS TOWN|\n",
      "|       ARK RIDGEMONT|\n",
      "|ARSENIC INDEPENDENCE|\n",
      "|   BOONDOCK BALLROOM|\n",
      "|       BUTCH PANTHER|\n",
      "|       CATCH AMISTAD|\n",
      "| CHINATOWN GLADIATOR|\n",
      "|      CHOCOLATE DUCK|\n",
      "|COMMANDMENTS EXPRESS|\n",
      "|    CROSSING DIVORCE|\n",
      "|     CROWDS TELEMARK|\n",
      "|    CRYSTAL BREAKING|\n",
      "|          DAZED PUNK|\n",
      "|DELIVERANCE MULHO...|\n",
      "|   FIREHOUSE VIETNAM|\n",
      "|       FLOATS GARDEN|\n",
      "|FRANKENSTEIN STRA...|\n",
      "|  GLADIATOR WESTWARD|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_df.\\\n",
    "    join(inventory_df, inventory_df.film_id==film_df.film_id, 'left')\\\n",
    "    .where(inventory_df.inventory_id.isNull())\\\n",
    "    .select(film_df.title)\\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.\n",
    "Вивести топ 3 актори, які найбільше зʼявлялись в категорії фільмів “Children”"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+\n",
      "|first_name|last_name|count_of_films|\n",
      "+----------+---------+--------------+\n",
      "|     HELEN|   VOIGHT|             7|\n",
      "|     SUSAN|    DAVIS|             6|\n",
      "|     RALPH|     CRUZ|             5|\n",
      "+----------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_df.\\\n",
    "    join(film_actor_df, film_df.film_id==film_actor_df.film_id, 'left').\\\n",
    "    join(film_category_df, film_df.film_id==film_category_df.film_id, 'left').\\\n",
    "    join(actor_df, actor_df.actor_id==film_actor_df.actor_id, 'left').\\\n",
    "    where(film_category_df.category_id == 3).\\\n",
    "    groupby(actor_df.first_name, actor_df.last_name).\\\n",
    "    agg(f.count(film_df.film_id).alias('count_of_films')).\\\n",
    "    orderBy(f.desc('count_of_films')).\\\n",
    "    limit(3).\\\n",
    "    show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6.\n",
    "Вивести міста з кількістю активних та неактивних клієнтів\n",
    "(в активних customer.active = 1).\n",
    "Результат відсортувати за кількістю неактивних клієнтів за спаданням."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+\n",
      "|city_id|Active_cust|No_active_cust|\n",
      "+-------+-----------+--------------+\n",
      "|    111|          0|             1|\n",
      "|    139|          0|             1|\n",
      "|    283|          0|             1|\n",
      "|    578|          0|             1|\n",
      "|    356|          0|             1|\n",
      "|     24|          0|             1|\n",
      "|    125|          0|             1|\n",
      "|    281|          0|             1|\n",
      "|    407|          0|             1|\n",
      "|     57|          0|             1|\n",
      "|    259|          0|             1|\n",
      "|    554|          0|             1|\n",
      "|    577|          0|             1|\n",
      "|    495|          0|             1|\n",
      "|    512|          0|             1|\n",
      "|    463|          1|             0|\n",
      "|    148|          1|             0|\n",
      "|    471|          1|             0|\n",
      "|    243|          1|             0|\n",
      "|    496|          1|             0|\n",
      "+-------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.\\\n",
    "    join(address_df, address_df.address_id==customer_df.address_id, 'left').\\\n",
    "    withColumn('No_active', f.when(customer_df.active==0, 1).otherwise(0)).\\\n",
    "    groupby('city_id').agg(f.sum('active').alias('Active_cust'), f.sum('No_active').alias('No_active_cust')).\\\n",
    "    orderBy(f.desc('No_active_cust')).\\\n",
    "    show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
